{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import os\n",
    "import keras \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras_radam import RAdam\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "random.seed(7)\n",
    "#tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.read_csv('./data/train.csv',index_col='id')\n",
    "test_ = pd. read_csv('./data/test.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train_.copy()\n",
    "test=test_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상청 데이터만 추출\n",
    "x_train = train.loc[:,'X00':'X39']\n",
    "\n",
    "# standardization을 위해 평균과 표준편차 구하기\n",
    "MEAN = x_train.mean()\n",
    "STD = x_train.std()\n",
    "\n",
    "# 표준편차가 0일 경우 대비하여 1e-07 추가 \n",
    "x_train = (x_train - MEAN) / (STD + 1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 모델에 입력 할 수 있는 시계열 형태로 데이터 변환 \n",
    "def convert_to_timeseries(df, interval):\n",
    "    sequence_list = []\n",
    "    target_list = []\n",
    "    \n",
    "    for i in tqdm(range(df.shape[0] - interval)):\n",
    "        sequence_list.append(np.array(df.iloc[i:i+interval,:-1]))\n",
    "        target_list.append(df.iloc[i+interval,-1])\n",
    "    \n",
    "    sequence = np.array(sequence_list)\n",
    "    target = np.array(target_list)\n",
    "    \n",
    "    return sequence, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_columns = ['Y15','Y16']\n",
    "#y_columns= train.iloc[:,40:-1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inte = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 4296/4296 [00:01<00:00, 2840.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 4296/4296 [00:01<00:00, 2789.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# t시점 이전 120분의 데이터로 t시점의 온도를 추정할 수 있는 학습데이터 형성\n",
    "sequence = np.empty((0, n_inte, 40))\n",
    "target = np.empty((0,))\n",
    "\n",
    "for column in y_columns :\n",
    "    \n",
    "    concat = pd.concat([x_train, train[column]], axis = 1)\n",
    "\n",
    "    _sequence, _target = convert_to_timeseries(concat.head(144*30), interval = n_inte)\n",
    "\n",
    "    sequence = np.vstack((sequence, _sequence))\n",
    "    target = np.hstack((target, _target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8592, 24, 40)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_to_timeseries 함수를 쓰기 위한 dummy feature 생성\n",
    "x_train['dummy'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에서 도출된 평균과 표준편차로 standardization 실시 \n",
    "test = (test - MEAN) / (STD + 1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert_to_timeseries 함수를 쓰기 위한 dummy feature 생성\n",
    "test['dummy'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 16248/16248 [00:06<00:00, 2609.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# train과 test 기간을 합쳐서 120분 간격으로 학습데이터 재구축\n",
    "x_test, _ = convert_to_timeseries(pd.concat([x_train, test], axis = 0), interval=n_inte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test set 기간인 후반부 80일에 맞게 자르기 \n",
    "x_test = x_test[-11520:, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만들어 두었던 dummy feature 제거\n",
    "x_train.drop('dummy', axis = 1, inplace = True)\n",
    "test.drop('dummy', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jungg\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# 간단한 lstm 모델 구축하기 \n",
    "simple_lstm_model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, input_shape=sequence.shape[-2:]),\n",
    "    keras.layers.Dense(64, activation='elu'),\n",
    "    keras.layers.Dense(32, activation='elu'),    \n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "simple_lstm_model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss가 4미만으로 떨어지면 학습 종료 시키는 기능\n",
    "class myCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        if(logs.get('loss') < 0.0001):\n",
    "            print('\\n Loss is under 0.0001, cancelling training')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 간단한 lstm 모델 구축하기 \n",
    "# simple_lstm_model = keras.models.Sequential([\n",
    "#     keras.layers.LSTM(64, input_shape=sequence.shape[-2:]),\n",
    "#     keras.layers.Dense(64, activation='elu'),\n",
    "#     keras.layers.Dense(32, activation='elu'),    \n",
    "#     keras.layers.Dense(1)\n",
    "# ])\n",
    "\n",
    "# simple_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "# # 모델 학습\n",
    "# simple_lstm_model.fit(sequence, target, epochs=60, batch_size=128, verbose=2,\n",
    "#     shuffle=False, callbacks = [callbacks], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jungg\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 7732 samples, validate on 860 samples\n",
      "Epoch 1/80\n",
      " - 2s - loss: 515.9444 - val_loss: 546.9694\n",
      "Epoch 2/80\n",
      " - 1s - loss: 402.4701 - val_loss: 385.5063\n",
      "Epoch 3/80\n",
      " - 1s - loss: 243.8521 - val_loss: 202.0478\n",
      "Epoch 4/80\n",
      " - 1s - loss: 129.7197 - val_loss: 85.1263\n",
      "Epoch 5/80\n",
      " - 1s - loss: 71.9710 - val_loss: 44.9100\n",
      "Epoch 6/80\n",
      " - 1s - loss: 46.5489 - val_loss: 29.9834\n",
      "Epoch 7/80\n",
      " - 1s - loss: 30.2111 - val_loss: 21.1113\n",
      "Epoch 8/80\n",
      " - 1s - loss: 21.9895 - val_loss: 16.1457\n",
      "Epoch 9/80\n",
      " - 1s - loss: 16.8409 - val_loss: 13.3638\n",
      "Epoch 10/80\n",
      " - 1s - loss: 13.0574 - val_loss: 10.6955\n",
      "Epoch 11/80\n",
      " - 1s - loss: 10.8491 - val_loss: 9.1543\n",
      "Epoch 12/80\n",
      " - 1s - loss: 9.4456 - val_loss: 8.3714\n",
      "Epoch 13/80\n",
      " - 1s - loss: 8.5378 - val_loss: 7.7496\n",
      "Epoch 14/80\n",
      " - 1s - loss: 7.8466 - val_loss: 7.2473\n",
      "Epoch 15/80\n",
      " - 1s - loss: 7.4046 - val_loss: 6.8924\n",
      "Epoch 16/80\n",
      " - 1s - loss: 7.0202 - val_loss: 6.6629\n",
      "Epoch 17/80\n",
      " - 1s - loss: 6.7110 - val_loss: 6.4416\n",
      "Epoch 18/80\n",
      " - 1s - loss: 6.4365 - val_loss: 6.2369\n",
      "Epoch 19/80\n",
      " - 1s - loss: 6.2356 - val_loss: 6.0608\n",
      "Epoch 20/80\n",
      " - 1s - loss: 6.0925 - val_loss: 5.8954\n",
      "Epoch 21/80\n",
      " - 1s - loss: 5.9574 - val_loss: 5.7411\n",
      "Epoch 22/80\n",
      " - 1s - loss: 5.8374 - val_loss: 5.6068\n",
      "Epoch 23/80\n",
      " - 1s - loss: 5.7369 - val_loss: 5.4842\n",
      "Epoch 24/80\n",
      " - 1s - loss: 5.6359 - val_loss: 5.3744\n",
      "Epoch 25/80\n",
      " - 1s - loss: 5.5510 - val_loss: 5.2797\n",
      "Epoch 26/80\n",
      " - 1s - loss: 5.4661 - val_loss: 5.1930\n",
      "Epoch 27/80\n",
      " - 1s - loss: 5.3840 - val_loss: 5.1260\n",
      "Epoch 28/80\n",
      " - 1s - loss: 5.3363 - val_loss: 5.0659\n",
      "Epoch 29/80\n",
      " - 1s - loss: 5.2563 - val_loss: 5.0054\n",
      "Epoch 30/80\n",
      " - 1s - loss: 5.1758 - val_loss: 4.9582\n",
      "Epoch 31/80\n",
      " - 1s - loss: 5.1158 - val_loss: 4.9097\n",
      "Epoch 32/80\n",
      " - 1s - loss: 5.0613 - val_loss: 4.8705\n",
      "Epoch 33/80\n",
      " - 1s - loss: 5.0123 - val_loss: 4.8305\n",
      "Epoch 34/80\n",
      " - 1s - loss: 4.9586 - val_loss: 4.7962\n",
      "Epoch 35/80\n",
      " - 1s - loss: 4.9186 - val_loss: 4.7576\n",
      "Epoch 36/80\n",
      " - 1s - loss: 4.8942 - val_loss: 4.7181\n",
      "Epoch 37/80\n",
      " - 1s - loss: 4.8454 - val_loss: 4.6936\n",
      "Epoch 38/80\n",
      " - 1s - loss: 4.8110 - val_loss: 4.6562\n",
      "Epoch 39/80\n",
      " - 1s - loss: 4.7828 - val_loss: 4.6259\n",
      "Epoch 40/80\n",
      " - 1s - loss: 4.7508 - val_loss: 4.5985\n",
      "Epoch 41/80\n",
      " - 1s - loss: 4.7195 - val_loss: 4.5701\n",
      "Epoch 42/80\n",
      " - 1s - loss: 4.6896 - val_loss: 4.5431\n",
      "Epoch 43/80\n",
      " - 1s - loss: 4.6607 - val_loss: 4.5175\n",
      "Epoch 44/80\n",
      " - 1s - loss: 4.6318 - val_loss: 4.4937\n",
      "Epoch 45/80\n",
      " - 1s - loss: 4.6035 - val_loss: 4.4711\n",
      "Epoch 46/80\n",
      " - 1s - loss: 4.5780 - val_loss: 4.4499\n",
      "Epoch 47/80\n",
      " - 1s - loss: 4.5532 - val_loss: 4.4298\n",
      "Epoch 48/80\n",
      " - 1s - loss: 4.5301 - val_loss: 4.4108\n",
      "Epoch 49/80\n",
      " - 1s - loss: 4.5077 - val_loss: 4.3927\n",
      "Epoch 50/80\n",
      " - 1s - loss: 4.4854 - val_loss: 4.3742\n",
      "Epoch 51/80\n",
      " - 1s - loss: 4.4655 - val_loss: 4.3575\n",
      "Epoch 52/80\n",
      " - 1s - loss: 4.4481 - val_loss: 4.3411\n",
      "Epoch 53/80\n",
      " - 1s - loss: 4.4254 - val_loss: 4.3261\n",
      "Epoch 54/80\n",
      " - 1s - loss: 4.3918 - val_loss: 4.3111\n",
      "Epoch 55/80\n",
      " - 1s - loss: 4.3869 - val_loss: 4.2890\n",
      "Epoch 56/80\n",
      " - 1s - loss: 4.3600 - val_loss: 4.3099\n",
      "Epoch 57/80\n",
      " - 1s - loss: 4.3461 - val_loss: 4.2561\n",
      "Epoch 58/80\n",
      " - 1s - loss: 4.3016 - val_loss: 4.3995\n",
      "Epoch 59/80\n",
      " - 1s - loss: 4.3125 - val_loss: 4.2730\n",
      "Epoch 60/80\n",
      " - 1s - loss: 4.5902 - val_loss: 4.2784\n",
      "Epoch 61/80\n",
      " - 1s - loss: 4.5092 - val_loss: 4.2095\n",
      "Epoch 62/80\n",
      " - 1s - loss: 4.3030 - val_loss: 4.2683\n",
      "Epoch 63/80\n",
      " - 1s - loss: 4.2553 - val_loss: 4.2795\n",
      "Epoch 64/80\n",
      " - 1s - loss: 4.1954 - val_loss: 4.2336\n",
      "Epoch 65/80\n",
      " - 1s - loss: 4.1318 - val_loss: 4.2243\n",
      "Epoch 66/80\n",
      " - 1s - loss: 4.1215 - val_loss: 4.2490\n",
      "Epoch 67/80\n",
      " - 2s - loss: 4.0856 - val_loss: 4.2010\n",
      "Epoch 68/80\n",
      " - 1s - loss: 4.1021 - val_loss: 4.2457\n",
      "Epoch 69/80\n",
      " - 1s - loss: 4.1033 - val_loss: 4.2319\n",
      "Epoch 70/80\n",
      " - 1s - loss: 4.0600 - val_loss: 4.2123\n",
      "Epoch 71/80\n",
      " - 1s - loss: 4.0356 - val_loss: 4.1823\n",
      "Epoch 72/80\n",
      " - 1s - loss: 4.0201 - val_loss: 4.2546\n",
      "Epoch 73/80\n",
      " - 1s - loss: 4.0079 - val_loss: 4.1845\n",
      "Epoch 74/80\n",
      " - 1s - loss: 3.9885 - val_loss: 4.3354\n",
      "Epoch 75/80\n",
      " - 1s - loss: 3.9672 - val_loss: 4.2029\n",
      "Epoch 76/80\n",
      " - 1s - loss: 3.9713 - val_loss: 4.4040\n",
      "Epoch 77/80\n",
      " - 1s - loss: 3.9518 - val_loss: 4.2209\n",
      "Epoch 78/80\n",
      " - 1s - loss: 3.9698 - val_loss: 4.2075\n",
      "Epoch 79/80\n",
      " - 1s - loss: 3.9420 - val_loss: 4.1437\n",
      "Epoch 80/80\n",
      " - 1s - loss: 3.8971 - val_loss: 4.2720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x272515e2f48>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 간단한 lstm 모델 구축하기 \n",
    "simple_lstm_model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, input_shape=sequence.shape[-2:]),\n",
    "#    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='elu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "simple_lstm_model.compile(optimizer=Adam(lr=0.001/2.), loss='mse')\n",
    "# 모델 학습\n",
    "simple_lstm_model.fit(sequence, target, epochs=80, batch_size=128, verbose=2,\n",
    "    shuffle=False, callbacks = [callbacks], validation_split=0.1)\n",
    "\n",
    "# Epoch 80/80\n",
    "#  - 1s - loss: 2.5424 - val_loss: 2.6561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 간단한 lstm 모델 구축하기 \n",
    "# simple_lstm_model = keras.models.Sequential([\n",
    "#     keras.layers.LSTM(64, input_shape=sequence.shape[-2:], activation='tanh'),\n",
    "#     keras.layers.Dense(64, activation='elu'),\n",
    "#     keras.layers.Dense(64, activation='elu'),\n",
    "#     keras.layers.Dense(64, activation='elu'),\n",
    "#     keras.layers.Dense(64, activation='elu'),    \n",
    "#     keras.layers.Dropout(0.05),\n",
    "#     keras.layers.Dense(1)\n",
    "# ])\n",
    "# simple_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "# # 모델 학습\n",
    "# simple_lstm_model.fit(sequence, target, epochs=80, batch_size=128, verbose=2,\n",
    "#     shuffle=False, callbacks = [callbacks], validation_split=0.1)\n",
    "\n",
    "# Epoch 80/80\n",
    "# - 1s - loss: 3.1128 - val_loss: 3.5588"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 간단한 lstm 모델 구축하기 \n",
    "# simple_lstm_model = keras.models.Sequential([\n",
    "#     keras.layers.LSTM(64, input_shape=sequence.shape[-2:], activation='tanh', return_sequences=True),\n",
    "#     keras.layers.LSTM(64),\n",
    "#     keras.layers.Dense(64, activation='elu'),    \n",
    "#     keras.layers.Dropout(0.05),\n",
    "#     keras.layers.Dense(1)\n",
    "# ])\n",
    "# simple_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "# # 모델 학습\n",
    "# simple_lstm_model.fit(sequence, target, epochs=80, batch_size=128, verbose=2,\n",
    "#     shuffle=False, callbacks = [callbacks], validation_split=0.1)\n",
    "\n",
    "# Epoch 79/80\n",
    "#  - 2s - loss: 2.8924 - val_loss: 3.3730\n",
    "# Epoch 80/80\n",
    "#  - 2s - loss: 2.7272 - val_loss: 3.1412\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 간단한 lstm 모델 구축하기 \n",
    "# simple_lstm_model = keras.models.Sequential([\n",
    "#     keras.layers.LSTM(64, input_shape=sequence.shape[-2:], activation='tanh', return_sequences=True),\n",
    "#     keras.layers.LSTM(64),\n",
    "#     keras.layers.Dense(64, activation='elu'),    \n",
    "#     keras.layers.Dropout(0.05),\n",
    "#     keras.layers.Dense(1)\n",
    "# ])\n",
    "# simple_lstm_model.compile(optimizer='adam', loss='mse')\n",
    "# # 모델 학습\n",
    "# simple_lstm_model.fit(sequence, target, epochs=80, batch_size=32, verbose=2,\n",
    "#     shuffle=False, callbacks = [callbacks], validation_split=0.1)\n",
    "\n",
    "# Epoch 78/80\n",
    "#  - 4s - loss: 2.0523 - val_loss: 2.3489\n",
    "# Epoch 79/80\n",
    "#  - 4s - loss: 2.2302 - val_loss: 2.2888\n",
    "# Epoch 80/80\n",
    "#  - 4s - loss: 2.0973 - val_loss: 3.1370"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 간단한 lstm 모델 구축하기 \n",
    "# simple_lstm_model = keras.models.Sequential([\n",
    "#     keras.layers.LSTM(256, input_shape=sequence.shape[-2:], activation='tanh'),\n",
    "# #    keras.layers.LSTM(64, activation='tanh'),\n",
    "#     keras.layers.Dense(256, activation='elu'),\n",
    "#     keras.layers.Dropout(0.2),\n",
    "#     keras.layers.Dense(1)\n",
    "# ])\n",
    "# simple_lstm_model.compile(optimizer=Adam(lr=1.e-4), loss='mse')\n",
    "# # 모델 학습\n",
    "# simple_lstm_model.fit(sequence, target, epochs=80, batch_size=256, verbose=2,\n",
    "#     shuffle=False, callbacks = [callbacks], validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM 레이어는 고정\n",
    "\n",
    "#simple_lstm_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 408/408 [00:00<00:00, 1262.52it/s]\n"
     ]
    }
   ],
   "source": [
    "# fine tuning 할 때 사용할 학습데이터 생성 (Y18)\n",
    "finetune_X, finetune_y = convert_to_timeseries(pd.concat([x_train.tail(432), train['Y18'].tail(432)], axis = 1), interval=n_inte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(408, 24, 40)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetune_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 399 samples, validate on 9 samples\n",
      "Epoch 1/30\n",
      " - 0s - loss: 6.6506 - val_loss: 4.6411\n",
      "Epoch 2/30\n",
      " - 0s - loss: 6.7680 - val_loss: 5.8535\n",
      "Epoch 3/30\n",
      " - 0s - loss: 3.7948 - val_loss: 3.1142\n",
      "Epoch 4/30\n",
      " - 0s - loss: 3.4055 - val_loss: 2.4223\n",
      "Epoch 5/30\n",
      " - 0s - loss: 3.0712 - val_loss: 2.1342\n",
      "Epoch 6/30\n",
      " - 0s - loss: 2.8509 - val_loss: 2.4088\n",
      "Epoch 7/30\n",
      " - 0s - loss: 2.4544 - val_loss: 1.9798\n",
      "Epoch 8/30\n",
      " - 0s - loss: 2.3041 - val_loss: 2.0394\n",
      "Epoch 9/30\n",
      " - 0s - loss: 2.0567 - val_loss: 1.9031\n",
      "Epoch 10/30\n",
      " - 0s - loss: 1.8873 - val_loss: 1.9321\n",
      "Epoch 11/30\n",
      " - 0s - loss: 1.7043 - val_loss: 1.9338\n",
      "Epoch 12/30\n",
      " - 0s - loss: 1.5527 - val_loss: 1.9821\n",
      "Epoch 13/30\n",
      " - 0s - loss: 1.4039 - val_loss: 2.0617\n",
      "Epoch 14/30\n",
      " - 0s - loss: 1.2784 - val_loss: 2.2193\n",
      "Epoch 15/30\n",
      " - 0s - loss: 1.1702 - val_loss: 2.3323\n",
      "Epoch 16/30\n",
      " - 0s - loss: 1.0705 - val_loss: 2.2881\n",
      "Epoch 17/30\n",
      " - 0s - loss: 1.0205 - val_loss: 2.3740\n",
      "Epoch 18/30\n",
      " - 0s - loss: 0.9485 - val_loss: 2.2672\n",
      "Epoch 19/30\n",
      " - 0s - loss: 0.9184 - val_loss: 2.3625\n",
      "Epoch 20/30\n",
      " - 0s - loss: 0.8551 - val_loss: 2.2623\n",
      "Epoch 21/30\n",
      " - 0s - loss: 0.8204 - val_loss: 2.2376\n",
      "Epoch 22/30\n",
      " - 0s - loss: 0.7837 - val_loss: 2.2093\n",
      "Epoch 23/30\n",
      " - 0s - loss: 0.7471 - val_loss: 2.1716\n",
      "Epoch 24/30\n",
      " - 0s - loss: 0.7157 - val_loss: 2.1397\n",
      "Epoch 25/30\n",
      " - 0s - loss: 0.6861 - val_loss: 2.1062\n",
      "Epoch 26/30\n",
      " - 0s - loss: 0.6584 - val_loss: 2.0518\n",
      "Epoch 27/30\n",
      " - 0s - loss: 0.6329 - val_loss: 1.9792\n",
      "Epoch 28/30\n",
      " - 0s - loss: 0.6104 - val_loss: 1.9095\n",
      "Epoch 29/30\n",
      " - 0s - loss: 0.5904 - val_loss: 1.8548\n",
      "Epoch 30/30\n",
      " - 0s - loss: 0.5716 - val_loss: 1.8091\n"
     ]
    }
   ],
   "source": [
    "# LSTM 레이어는 고정 시켜두고, DNN 레이어에 대해서 fine tuning 진행 (Transfer Learning)\n",
    "finetune_history = simple_lstm_model.fit( finetune_X, finetune_y, epochs=30,\n",
    "            batch_size=20, shuffle=False, verbose = 2, validation_split=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측하기 \n",
    "finetune_pred = simple_lstm_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 만들기\n",
    "submit = pd.DataFrame({'id':range(144*33, 144*113),\n",
    "              'Y18':finetune_pred.reshape(1,-1)[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('baseline_result.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
